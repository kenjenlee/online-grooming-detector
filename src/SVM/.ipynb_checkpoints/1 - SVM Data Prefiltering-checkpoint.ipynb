{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - SVM Data Prefiltering\n",
    "This series of notebook will be used for the SVM implementation for online grooming. We will re-implement the SVM suggested by Villatoro-Tello et al. in the paper \"A Two-step Approach for Effective Detection of Misbehaving Users in Chats\".\n",
    "\n",
    "### Prefiltering Training Data\n",
    "First, we want to do the required pre-filtering of training data. Any conversation meeting any of the following criteria are removed:\n",
    "1. conversations with only one participant\n",
    "2. conversations with each user having 6 or less messages\n",
    "3. conversations with long sequences of unrecognized characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "\n",
    "train_data_path = \"../../data/pan12-sexual-predator-identification-training-corpus-2012-05-01/\"\n",
    "test_data_path = \"../../data/pan12-sexual-predator-identification-test-corpus-2012-05-21/\"\n",
    "\n",
    "training_xml = ET.parse(train_data_path + 'pan12-sexual-predator-identification-training-corpus-2012-05-01.xml')\n",
    "root = training_xml.getroot()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now root stores the xml file in a nested list, let's remove conversations meeting the first criteria: conversations with only one participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 12773 out of 66927 conversations\n"
     ]
    }
   ],
   "source": [
    "conv_2_remove = []\n",
    "authors = []\n",
    "init_len = len(root)\n",
    "\n",
    "for conversation in root:\n",
    "    authors.clear()\n",
    "    \n",
    "    # find all unique authors in this conversation\n",
    "    for message in conversation:\n",
    "        author = message.find('author').text\n",
    "        if author not in authors:\n",
    "            authors.append(author)\n",
    "    \n",
    "    # remove if one or less authors\n",
    "#     if (len(authors)) <= 1:\n",
    "#         root.remove(conversation)\n",
    "    if (len(authors)) <= 1 and \\\n",
    "    conversation.get('id') not in conv_2_remove:\n",
    "        conv_2_remove.append(conversation.get('id'))\n",
    "\n",
    "# print(\"Removing {} out of {} conversations\".format(init_len - len(root), init_len))\n",
    "print(\"Removing {} out of {} conversations\".format(len(conv_2_remove), init_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now removed 12773 conversations. Next we remove all conversations that meet the second criteria: conversations with each user having 5 or less messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 51827 out of 66927 conversations\n"
     ]
    }
   ],
   "source": [
    "for conversation in root:\n",
    "    if conversation.get('id') in conv_2_remove:\n",
    "        continue\n",
    "    authors = {}\n",
    "    for message in conversation:\n",
    "        author = message.find('author').text\n",
    "        if author in authors:\n",
    "            authors[author] = authors[author] + 1\n",
    "        else:\n",
    "            authors[author] = 1\n",
    "    remove = True\n",
    "    for author in authors:\n",
    "        if authors[author] > 5:\n",
    "            remove = False\n",
    "            \n",
    "#     if remove is True:\n",
    "#         root.remove(conversation)\n",
    "    if remove is True and \\\n",
    "    conversation.get('id') not in conv_2_remove:\n",
    "        conv_2_remove.append(conversation.get('id'))\n",
    "\n",
    "# print(\"Removing {} out of {} conversations\".format(init_len - len(root), init_len))\n",
    "print(\"Removing {} out of {} conversations\".format(len(conv_2_remove), init_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now removed 51827 conversations out of the original 66927. Lastly we will remove any conversations with messages containing long sequences of unrecognized characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 52224 out of 66927 conversations\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for conversation in root:\n",
    "    if conversation.get('id') in conv_2_remove:\n",
    "        continue\n",
    "    remove = False\n",
    "    for message in conversation:\n",
    "        text = message.find(\"text\").text\n",
    "        if text is None or len(text) < 20:\n",
    "            continue\n",
    "        match_str = re.findall(\"[\\W_]\", text)\n",
    "        if len(match_str) / len(text) > 0.6:\n",
    "            remove = True\n",
    "            break\n",
    "#     if remove is True:\n",
    "#         root.remove(conversation)\n",
    "    if remove is True and \\\n",
    "        conversation.get('id') not in conv_2_remove:\n",
    "            conv_2_remove.append(conversation.get('id'))\n",
    "\n",
    "print(\"Removing {} out of {} conversations\".format(len(conv_2_remove), init_len))\n",
    "# print(\"Removing {} out of {} conversations\".format(init_len - len(root), init_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now removed 52224 out of 66927 conversations. Next we remove the conversations we want to remove from root itself and write the new xml back into aother file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new root has a length of 14703.\n"
     ]
    }
   ],
   "source": [
    "for conversation in root.findall('conversation'):\n",
    "    if conversation.get('id') in conv_2_remove:\n",
    "        root.remove(conversation)\n",
    "print(\"The new root has a length of {}.\".format(len(root)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data written!\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import ElementTree\n",
    "tree = ElementTree(root)\n",
    "tree.write(open('../../data/svm_training_data/training_data.xml', 'wb'))\n",
    "print(\"Filtered data written!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
